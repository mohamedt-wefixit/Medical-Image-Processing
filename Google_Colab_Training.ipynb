{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check GPU and System Setup\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"System Check:\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"Warning: No GPU detected - training will be very slow!\")\n",
    "\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "print(f\"Python version: {torch.version.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Install Required Packages\n",
    "!pip install nibabel scipy pyyaml scikit-learn matplotlib tensorboard tqdm pandas seaborn\n",
    "\n",
    "print(\"\\nAll requirements installed!\")\n",
    "print(\"Packages installed:\")\n",
    "print(\"  - nibabel (NIfTI medical image handling)\")\n",
    "print(\"  - torch (Deep learning)\")\n",
    "print(\"  - scipy (Scientific computing)\")\n",
    "print(\"  - matplotlib (Plotting)\")\n",
    "print(\"  - tensorboard (Training visualization)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Check Dataset Structure\n",
    "print(\"Checking uploaded files...\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\nMM-WHS Dataset structure:\")\n",
    "!ls -la 'MM-WHS 2017 Dataset'/\n",
    "\n",
    "print(\"\\nChecking for medical image files:\")\n",
    "!find 'MM-WHS 2017 Dataset' -name \"*.nii.gz\" | head -10\n",
    "\n",
    "print(\"\\nFile types in mr_train:\")\n",
    "!find 'MM-WHS 2017 Dataset/mr_train' -name \"*.nii.gz\" | sed 's/.*\\///' | sort\n",
    "\n",
    "print(\"\\nTotal files per directory:\")\n",
    "for subdir in ['mr_train', 'mr_test', 'ct_train', 'ct_test']:\n",
    "    print(f\"{subdir}:\")\n",
    "    !find 'MM-WHS 2017 Dataset'/'{subdir}' -name \"*.nii.gz\" | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare for Training\n",
    "\n",
    "# Create necessary directories\n",
    "!mkdir -p runs/dof_regression\n",
    "!mkdir -p checkpoints\n",
    "!mkdir -p synthetic_training_data\n",
    "\n",
    "print(\"Created training directories\")\n",
    "\n",
    "# Check if we have actual image files or just labels\n",
    "image_files = !find 'MM-WHS 2017 Dataset' -name \"*image*.nii.gz\"\n",
    "label_files = !find 'MM-WHS 2017 Dataset' -name \"*label*.nii.gz\"\n",
    "all_files = !find 'MM-WHS 2017 Dataset/mr_train' -name \"*.nii.gz\"\n",
    "\n",
    "print(f\"\\nDataset Analysis:\")\n",
    "print(f\"Image files found: {len(image_files)}\")\n",
    "print(f\"Label files found: {len(label_files)}\")\n",
    "print(f\"Total mr_train files: {len(all_files)}\")\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"\\nWarning: No image files found! The dataset might only contain labels.\")\n",
    "    print(\"We'll adapt the code to work with available files...\")\n",
    "    \n",
    "    # Check what files we actually have\n",
    "    print(\"\\nAvailable files in mr_train:\")\n",
    "    !ls 'MM-WHS 2017 Dataset/mr_train'/ | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate Training Data\n",
    "print(\"Generating synthetic training data...\")\n",
    "!python generate_training_data.py\n",
    "print(\"\\nTraining data generation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Train the Model\n",
    "# Create necessary directories\n",
    "!mkdir -p runs/dof_regression\n",
    "!mkdir -p checkpoints\n",
    "!mkdir -p synthetic_training_data\n",
    "\n",
    "# Check if synthetic data was generated\n",
    "print(\"Checking synthetic training data...\")\n",
    "!ls -la synthetic_training_data/ | head -5\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting model training (this will take 30-60 minutes)...\")\n",
    "\n",
    "# Start training\n",
    "!python dof_regressor_model.py --metadata-dir synthetic_training_data\n",
    "print(\"\\nModel training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Check Results\n",
    "print(\"Files created during training:\")\n",
    "!ls -la checkpoints/\n",
    "print(\"\\nTraining logs:\")\n",
    "!ls -la runs/dof_regression/\n",
    "print(\"\\nModel file size:\")\n",
    "!du -h checkpoints/best_checkpoint.pth 2>/dev/null || echo \"Model file not found\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"Your trained model: checkpoints/best_checkpoint.pth\") \n",
    "print(\"Training logs: runs/dof_regression/\")\n",
    "print(\"Demo script: demo.py\")\n",
    "print(\"\\nDownload these files to deliver to your client!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Run Demo\n",
    "!python demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Download Trained Model\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading trained model...\")\n",
    "files.download('checkpoints/best_checkpoint.pth')\n",
    "print(\"Download complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
